# LLM Inference

- [LLM Inference](#llm-inference) 
	- [Survey](#survey)
	- [LLM Inference](#llm-inference-1)
	- [Speculative Decoding](#speculative-decoding)
	- [VLLM](#vllm)
	- [Toolkits](#toolkits)
	- [Misc](#misc)


## Survey


## LLM Inference
- **The End of Manual Decoding: Towards Truly End-to-End Language Models**, `arXiv, 2510.26697`, [arxiv](http://arxiv.org/abs/2510.26697v1), [pdf](http://arxiv.org/pdf/2510.26697v1.pdf), cication: [**-1**](None) 

	 *Zhichao Wang, Dongyang Ma, Xinting Huang, ..., Xiaoying Tang, Yan Wang*


## Speculative Decoding
- **Batch Speculative Decoding Done Right**, `arXiv, 2510.22876`, [arxiv](http://arxiv.org/abs/2510.22876v1), [pdf](http://arxiv.org/pdf/2510.22876v1.pdf), cication: [**-1**](None) 

	 *Ranran Haoran Zhang, Soumik Dey, Ashirbad Mishra, ..., Binbin Li, Rui Zhang*


## VLLM

- [Continuous batching](https://huggingface.co/blog/continuous_batching)  ðŸ¤—
- [**nano-vllm**](https://github.com/GeeeekExplorer/nano-vllm) - GeeeekExplorer ![Star](https://img.shields.io/github/stars/GeeeekExplorer/nano-vllm) 
- [No More Retokenization Drift: Returning Token IDs via the OpenAI Compatible API Matters in Agent RL](https://blog.vllm.ai/2025/10/22/agent-lightning.html) 

## Toolkits


## Misc