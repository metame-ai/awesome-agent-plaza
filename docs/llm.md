# LLM Basics

- [LLM Basics](#llm-basics) 
	- [LLM Insight](#llm-insight)
	- [LLM Hallucination](#llm-hallucination)
	- [LLM Omni](#llm-omni)
	- [LLM Tutorial](#llm-tutorial)
	- [Open-source LLM](#open-source-llm)


## LLM Insight

- [Emergent Introspective Awareness in Large Language Models](https://transformer-circuits.pub/2025/introspection/index.html) 
- [Signs of introspection in large language models](https://www.anthropic.com/research/introspection) 
- **Verifying Chain-of-Thought Reasoning via Its Computational Graph**, `arXiv, 2510.09312`, [arxiv](http://arxiv.org/abs/2510.09312v1), [pdf](http://arxiv.org/pdf/2510.09312v1.pdf), cication: [**-1**](None) 

	 *Zheng Zhao, Yeskendir Koishekenov, Xianjun Yang, ..., Naila Murray, Nicola Cancedda*
- ðŸŒŸ **The Dragon Hatchling: The Missing Link between the Transformer and 
  Models of the Brain**, `arXiv, 2509.26507`, [arxiv](http://arxiv.org/abs/2509.26507v1), [pdf](http://arxiv.org/pdf/2509.26507v1.pdf), cication: [**-1**](None) 

	 *Adrian Kosowski, PrzemysÅ‚aw UznaÅ„ski, Jan Chorowski, ..., Zuzanna Stamirowska, MichaÅ‚ Bartoszkiewicz*


## LLM Hallucination
- **Learning to Reason for Hallucination Span Detection**, `arXiv, 2510.02173`, [arxiv](http://arxiv.org/abs/2510.02173v2), [pdf](http://arxiv.org/pdf/2510.02173v2.pdf), cication: [**-1**](None) 

	 *Hsuan Su, Ting-Yao Hu, Hema Swetha Koppula, ..., Oncel Tuzel, Raviteja Vemulapalli*
- **When Models Lie, We Learn: Multilingual Span-Level Hallucination 
  Detection with PsiloQA**, `arXiv, 2510.04849`, [arxiv](http://arxiv.org/abs/2510.04849v1), [pdf](http://arxiv.org/pdf/2510.04849v1.pdf), cication: [**-1**](None) 

	 *Elisei Rykov, Kseniia Petrushina, Maksim Savkin, ..., Vasily Konovalov, Julia Belikova*


## LLM Omni
- **Ming-Flash-Omni: A Sparse, Unified Architecture for Multimodal 
  Perception and Generation**, `arXiv, 2510.24821`, [arxiv](http://arxiv.org/abs/2510.24821v1), [pdf](http://arxiv.org/pdf/2510.24821v1.pdf), cication: [**-1**](None) 

	 *Inclusion AI, :, Bowen Ma, ..., Zizheng Yang, Zhengyu He*
- **OmniVinci: Enhancing Architecture and Data for Omni-Modal Understanding 
  LLM**, `arXiv, 2510.15870`, [arxiv](http://arxiv.org/abs/2510.15870v2), [pdf](http://arxiv.org/pdf/2510.15870v2.pdf), cication: [**-1**](None) 

	 *Hanrong Ye, Chao-Han Huck Yang, Arushi Goel, ..., Hongxu Yin, Pavlo Molchanov*
- **Qwen3-Omni Technical Report**, `arXiv, 2509.17765`, [arxiv](http://arxiv.org/abs/2509.17765v1), [pdf](http://arxiv.org/pdf/2509.17765v1.pdf), cication: [**-1**](None) 

	 *Jin Xu, Zhifang Guo, Hangrui Hu, ..., Jingren Zhou, Junyang Lin*


## LLM Tutorial
- ðŸŒŸ [The Smol Training Playbook:](https://huggingface.co/spaces/HuggingFaceTB/smol-playbook-toc)  ðŸ¤— 
- [**modded-nanogpt**](https://github.com/KellerJordan/modded-nanogpt) - KellerJordan ![Star](https://img.shields.io/github/stars/KellerJordan/modded-nanogpt.svg?style=social&label=Star) 
- [**nanoGPT**](https://github.com/karpathy/nanoGPT) - karpathy ![Star](https://img.shields.io/github/stars/karpathy/nanoGPT.svg?style=social&label=Star) 


## Open-source LLM
- **SmolLM2: When Smol Goes Big -- Data-Centric Training of a Small Language 
  Model**, `arXiv, 2502.02737`, [arxiv](http://arxiv.org/abs/2502.02737v1), [pdf](http://arxiv.org/pdf/2502.02737v1.pdf), cication: [**-1**](None) 

	 *Loubna Ben Allal, Anton Lozhkov, Elie Bakouch, ..., Leandro von Werra, Thomas Wolf*