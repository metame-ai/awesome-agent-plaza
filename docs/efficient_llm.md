# Efficient LLM

- [Efficient LLM](#efficient-llm) 
  - [Survey](#survey)
  - [Efficient LLM](#efficient-llm-1)
  - [Distillation](#distillation)
  - [PEFT](#peft)
  - [LoRA](#lora)
  - [Quantization](#quantization)
  - [Pruning](#pruning)
  - [Toolkits](#toolkits)
  - [Misc](#misc)


## Survey


## Efficient LLM


## Distillation


## PEFT

- **PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models**, `arXiv, 2404.02948`, [arxiv](https://arxiv.org/abs/2404.02948v4), [pdf](https://arxiv.org/pdf/2404.02948v4.pdf), cication: [**-1**](None) 

	 *Fanxu Meng, Zhaohui Wang, Muhan Zhang*

## LoRA


## Quantization

- **Quantization-Aware Distillation for NVFP4 Inference Accuracy Recovery**, `arXiv, 2601.20088`, [arxiv](https://arxiv.org/abs/2601.20088v1), [pdf](https://arxiv.org/pdf/2601.20088v1.pdf), cication: [**-1**](None) 

	 *Meng Xin, Sweta Priyadarshi, Jingyu Xin, ..., Tijmen Blankevoort, Huizi Mao*

## Pruning


## Toolkits


## Misc