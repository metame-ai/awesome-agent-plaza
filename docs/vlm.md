# Vision Language Models

- [Vision Language Models](#vision-language-models) 
	- [Survey](#survey)
	- [VLM](#vlm)
	- [OCR](#ocr)
	- [Open VLM](#open-vlm)
	- [Open-source VLM](#open-source-vlm)
	- [Toolkits](#toolkits)
	- [Misc](#misc)


## Survey


## VLM

- **Visual Spatial Tuning**, `arXiv, 2511.05491`, [arxiv](https://arxiv.org/abs/2511.05491v1), [pdf](https://arxiv.org/pdf/2511.05491v1.pdf), cication: [**-1**](None) 

	 *Rui Yang, Ziyu Zhu, Yanwei Li, ..., Yi Lin, Hengshuang Zhao*
  Scale**, `arXiv, 2510.14979`, [arxiv](http://arxiv.org/abs/2510.14979v1), [pdf](http://arxiv.org/pdf/2510.14979v1.pdf), cication: [**-1**](None) 

	 *Haiwen Diao, Mingxuan Li, Silei Wu, ..., Dahua Lin, Ziwei Liu*

## OCR
- [olmOCR 2: Unit test rewards for document OCR](https://allenai.org/blog/olmocr-2) 


## Open VLM
- **Apriel-1.5-15b-Thinker**, `arXiv, 2510.01141`, [arxiv](http://arxiv.org/abs/2510.01141v1), [pdf](http://arxiv.org/pdf/2510.01141v1.pdf), cication: [**-1**](None) 

	 *Shruthan Radhakrishna, Aman Tiwari, Aanjaneya Shukla, ..., Srinivas Sunkara, Nicholas Chapados*

## Open-source VLM

- [Molmo 2: State-of-the-art video understanding, pointing, and tracking](https://allenai.org/blog/molmo2) 
- **NVIDIA Nemotron Nano V2 VL**, `arXiv, 2511.03929`, [arxiv](https://arxiv.org/abs/2511.03929v2), [pdf](https://arxiv.org/pdf/2511.03929v2.pdf), cication: [**-1**](None) 

	 *NVIDIA, :, Amala Sanjay Deshmukh, ..., Andrew Tao, Bryan Catanzaro*

	 *NVIDIA, :, Amala Sanjay Deshmukh, ..., Andrew Tao, Bryan Catanzaro*


## Toolkits


## Misc
## Data
- [Molmo2 Data](https://huggingface.co/collections/allenai/molmo2-data)  ðŸ¤— 